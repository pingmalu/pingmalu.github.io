---
layout: post
title:  "MongoDB脚本"
---

记录MongoDB日常使用到的脚本

# 建立复合索引

	db.getCollection("bolg").createIndex({"source":1,"date":-1});

1 为指定按升序创建索引

-1 为降序来创建索引

# 查看今日爬虫状态

{% highlight js %}
/*
* 查看今日爬虫状态
* BY: http://malu.me/
*/
var date = new Date();
var bb = date.getFullYear()+'-'+(date.getMonth()+1)+'-'+date.getDate();
function getcount(){
    var collection_list = db.getCollectionInfos({"name":/BR_/});  // 列出前包含BR_的Collection
    for ( var i=0;i<collection_list.length;i++ ){
        table = collection_list[i]['name'];
        ok = db.getCollection(table).find({'product_info': {$ne:""},"date":bb,"source":"TB"}).count();
        no = db.getCollection(table).find({'product_info': "","date":bb,"source":"TB"}).count();
        print(table, ok+'/'+no);
    }
}
getcount();
{% endhighlight %}


# 创建唯一索引，并消除重复数据。

数字1表示userid键的索引按升序存储，-1表示userid键的索引按照降序方式存储。

    > db.test.ensureIndex({"userid":1},{"unique":true,"dropDups":true}) 

注：如果存在其他键，那么删除重复会失败，需要手动删除。    


# 聚合查询，统计重复个数

	> db.runCommand({"distinct":"table_name","key":"field_name"})

	# 查看非重复值个数
	> db.getCollection("table_name").distinct('field_name').length

	# 找出指定字段重复数
	> db.AI_online.aggregate([{$group : {_id : "$title", num : {$sum : 1}}},{$match :{num:{$gt : 1}}},{$sort:{num:-1}}])

	# 删除指定字段重复值，只保留一个（去重）
	> db.AI_online.aggregate([
    {
        $group: { _id: {title: '$title'},count: {$sum: 1},dups: {$addToSet: '$_id'}}
    },
    {
        $match: {count: {$gt: 1}}
    }
	]).forEach(function(doc){
	    doc.dups.shift();
	    db.AI_online.remove({_id: {$in: doc.dups}});
	})



# 模糊查询

	db.test_info.find({"tname": {$regex: '测试', $options:'i'}}) 

	db.test_info.find({"tname": {$regex:/测试.*/i}})

# 模糊+或查询

	db.test_info.find({"$or":[{"title":{$regex:/测试.*/i}},{"summary":{$regex:/测试.*/i}}]}) 

# 运维脚本

## 备份整个数据库

	#!/bin/bash
	MY_PATH=$(cd "$(dirname "$0")"; pwd)
	cd $MY_PATH
	dd=`date '+%Y-%m-%d-%H%M%S'`
	mongodump -o ./$dd --gzip --uri=mongodb://admin:passwd@localhost:27017/?authSource=admin

## 恢复整个数据库

	mongorestore -h localhost:27017 --gzip --dir=backup_dir