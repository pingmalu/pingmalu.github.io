---
layout: post
title:  "elk6安装过程"
---


logstash是一个数据分析软件，主要目的是分析log日志。整一套软件可以当作一个MVC模型，logstash是controller层，Elasticsearch是一个model层，kibana是view层。

首先将数据传给logstash，它将数据进行过滤和格式化（转成JSON格式），然后传给Elasticsearch进行存储、建搜索的索引，kibana提供前端的页面再进行搜索和图表可视化，它是调用Elasticsearch的接口返回的数据进行可视化。logstash和Elasticsearch是用Java写的，kibana使用node.js框架。


1.安装java环境

    apt install openjdk-8-jre-headless

2.安装elasticsearch

    wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.2.deb
    dpkg -i elasticsearch-6.3.2.deb

2.1.安装elasticsearch-head插件

    git clone https://github.com/mobz/elasticsearch-head.git  
    cd elasticsearch-head  
    npm install
    # 如果报错 npm ERR! Failed at the phantomjs-prebuilt@2.1.16 install script ，则安装
    npm install phantomjs-prebuilt@2.1.16 --ignore-scripts
    npm run start

安装完head插件需要把elasticsearch的跨域访问开启，往elasticsearch.yml添加

    #allow origin
    http.cors.enabled: true
    http.cors.allow-origin: "*"


3.安装logstash

    wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.2.deb
    dpkg -i logstash-6.3.2.deb

3.1.添加logstash配置文件

    cat /etc/logstash/conf.d/logstash.conf

    input {
        file {
            path => "/app/log/*.log"
            start_position => beginning
            sincedb_path => "/tmp/logstash.db"
        }
    }
    filter {
        grok {
            match => { "message" => "%{COMBINEDAPACHELOG}"}
        }
        date {
            locale => "en"
            match => ["timestamp" , "dd/MMM/YYYY:HH:mm:ss Z"]
        }
        geoip {
            source => "clientip"
        }
        if [@timestamp] < "2018-08-17" {
            drop {}
        }
    }
    output {
        elasticsearch {
             index => "logstash-16988.com"
             workers => 5
             hosts => "localhost:9200"
        }
    }


logstash 日期转换成时间戳

    filter {
        grok {
            match => { "message" => "%{COMBINEDAPACHELOG}"}
        }
        date {
            locale => "en"
            match => ["timestamp" ,"dd/MMM/YYYY:HH:mm:ss Z"]
            target => "pubdate"
        }
        ruby {    
            code => 'event.set("pubdate",event.get("pubdate").to_i)'  
        }
    }

logstash.conf 根据file内的日期过滤，例如只导10天以内的数据

    filter {
        grok {
            match => { "message" => "%{COMBINEDAPACHELOG}"}
        }
        date {
            locale => "en"
            match => ["timestamp" ,"dd/MMM/YYYY:HH:mm:ss Z"]
        }
        geoip {
            source => "clientip"
        }
        ruby {    
            code => 'if event.get("[@timestamp]").to_i < ( Time.now - 864000).to_i
                event.cancel
            end'  
        }
    }



3.2.运行logstash

    /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/


3.3.logstash的sincedb_path读取进度记录

    /usr/share/logstash/data/plugins/inputs/file/


4.安装kibana

    wget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.2-amd64.deb
    dpkg -i kibana-6.3.2-amd64.deb

4.1.修改kibana监听地址

    vim /etc/kibana/kibana.yml
    server.host: "0.0.0.0"



# 其他

## elasticsearch-head 通过base auth访问es

    http://localhost:9100/?base_uri=http://localhost:9200&auth_user=elastic&auth_password=password

## 默认端口

    elasticsearch集群通讯端口     :9300
    elasticsearch                 :9200
    elasticsearch-head            :9100
    kibana                        :5601



# ES操作

查看总数：

    GET /logstash-*/_count?pretty

获取一条：

    索引库/类型/ID

    GET /{index}/{type}/{id}

添加一条：

    PUT /{index}/{type}/{id}
    {
      "field": "value",
      ...
    }

查询：

    POST /{index}/_search
    {"query":{"range":{"@timestamp":{"lt":"2018-08-17"}}}}


查询删除：

    POST /{index}/_delete_by_query
    {"query":{"range":{"@timestamp":{"lt":"2018-08-17"}}}}

删除索引:

    DEL /{index}


设置副本数量

    PUT /_settings
    {
        "number_of_replicas": 0
    }

创建只有 一个主分片，没有副本的小索引：

    PUT /my_temp_index
    {
        "settings": {
            "number_of_shards" :   1,
            "number_of_replicas" : 0
        }
    }

    number_of_shards
    每个索引的主分片数，默认值是 5 。这个配置在索引创建后不能修改。
    number_of_replicas
    每个主分片的副本数，默认值是 1 。对于活动的索引库，这个配置可以随时修改。

